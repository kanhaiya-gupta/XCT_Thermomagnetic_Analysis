{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Analysis Pipeline\n",
    "\n",
    "This notebook demonstrates a complete end-to-end analysis workflow, integrating all framework capabilities. Learn how to:\n",
    "\n",
    "- **Run complete analysis pipeline** from data loading to reporting\n",
    "- **Integrate all analysis modules** (core, preprocessing, experimental, quality)\n",
    "- **Generate comprehensive reports** with visualizations\n",
    "- **Export results** in multiple formats\n",
    "- **Create reproducibility packages** for sharing and validation\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Execute a complete analysis workflow from start to finish\n",
    "2. Integrate multiple analysis types in a single pipeline\n",
    "3. Generate comprehensive reports and visualizations\n",
    "4. Export results for external tools (DragonFly, etc.)\n",
    "5. Create reproducibility packages\n",
    "\n",
    "## ‚ö†Ô∏è Prerequisites\n",
    "\n",
    "- **All previous notebooks**: Understanding of individual analysis modules\n",
    "- **Required packages**: Same as previous notebooks\n",
    "- **XCT data**: Raw or segmented volume data\n",
    "\n",
    "## üìñ Usage\n",
    "\n",
    "1. Run all cells to initialize the widgets\n",
    "2. Configure the complete pipeline\n",
    "3. Select analysis modules to include\n",
    "4. Run the complete pipeline\n",
    "5. Review comprehensive results\n",
    "6. Export reports and reproducibility packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Complete Analysis Pipeline\n",
      "   Project root: /mnt/c/Users/kanha/Independent_Research/pbf-lbm-nosql-data-warehouse/XCT_Thermomagnetic_Analysis\n",
      "   Widgets available: True\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "import json\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Check for ipywidgets\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from ipywidgets import HBox, VBox, Output, Tab, interactive\n",
    "    from IPython.display import display, clear_output, HTML\n",
    "    WIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WIDGETS_AVAILABLE = False\n",
    "    print(\"‚ùå ipywidgets not available!\")\n",
    "    print(\"   Install with: pip install ipywidgets\")\n",
    "\n",
    "# Find project root\n",
    "current_dir = Path().resolve()\n",
    "if current_dir.name == 'notebooks':\n",
    "    project_root = current_dir.parent\n",
    "elif (current_dir / 'src').exists():\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "# Add to path\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "print(\"üì¶ Complete Analysis Pipeline\")\n",
    "print(f\"   Project root: {project_root}\")\n",
    "print(f\"   Widgets available: {WIDGETS_AVAILABLE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Framework Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All modules loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load all framework modules\n",
    "try:\n",
    "    from src.analyzer import XCTAnalyzer\n",
    "    from src.core.metrics import compute_all_metrics\n",
    "    from src.core.porosity import analyze_porosity_distribution\n",
    "    from src.core.filament_analysis import estimate_filament_diameter\n",
    "    from src.preprocessing.preprocessing import apply_filters\n",
    "    from src.experimental.flow_analysis import comprehensive_flow_analysis\n",
    "    from src.experimental.thermal_analysis import compute_thermal_resistance\n",
    "    from src.experimental.energy_conversion import estimate_power_output\n",
    "    from src.quality.dimensional_accuracy import comprehensive_dimensional_analysis\n",
    "    from src.quality.uncertainty_analysis import comprehensive_uncertainty_analysis\n",
    "    from src.quality.reproducibility import export_reproducibility_package\n",
    "    from src.integration.dragonfly_integration import comprehensive_dragonfly_integration\n",
    "    from src.core.visualization import create_analysis_report\n",
    "    from src.utils.utils import load_volume, normalize_path\n",
    "    \n",
    "    print(\"‚úÖ All modules loaded successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error loading modules: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Complete Pipeline Dashboard\n",
    "\n",
    "Use the interactive widgets below to configure and run a complete analysis pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Creating interactive widgets...\n",
      "‚úÖ Widgets created successfully!\n"
     ]
    }
   ],
   "source": [
    "if not WIDGETS_AVAILABLE:\n",
    "    print(\"‚ùå Cannot create widgets - ipywidgets not available\")\n",
    "else:\n",
    "    print(\"üé® Creating interactive widgets...\")\n",
    "    \n",
    "    # Initialize state\n",
    "    analyzer = None\n",
    "    pipeline_results = {}\n",
    "    \n",
    "    # ============================================\n",
    "    # Section 1: Data Loading\n",
    "    # ============================================\n",
    "    \n",
    "    file_path_text = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Enter file path to XCT volume',\n",
    "        description='File Path:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "    \n",
    "    file_format_dropdown = widgets.Dropdown(\n",
    "        options=['Auto-detect', 'DICOM', 'TIFF', 'RAW', 'NIfTI', 'NumPy'],\n",
    "        value='Auto-detect',\n",
    "        description='Format:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    voxel_size_x = widgets.FloatText(value=0.1, description='Voxel X (mm):', style={'description_width': 'initial'})\n",
    "    voxel_size_y = widgets.FloatText(value=0.1, description='Voxel Y (mm):', style={'description_width': 'initial'})\n",
    "    voxel_size_z = widgets.FloatText(value=0.1, description='Voxel Z (mm):', style={'description_width': 'initial'})\n",
    "    \n",
    "    sample_name_text = widgets.Text(\n",
    "        value='sample',\n",
    "        description='Sample Name:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    load_button = widgets.Button(\n",
    "        description='üìÇ Load Volume',\n",
    "        button_style='primary',\n",
    "        layout=widgets.Layout(width='150px', height='40px')\n",
    "    )\n",
    "    \n",
    "    volume_info_display = widgets.HTML(\n",
    "        value=\"<p><i>No volume loaded</i></p>\",\n",
    "        layout=widgets.Layout(height='100px', overflow='auto')\n",
    "    )\n",
    "    \n",
    "    # ============================================\n",
    "    # Section 2: Pipeline Configuration\n",
    "    # ============================================\n",
    "    \n",
    "    widgets.HTML(\"<h3>üìã Analysis Modules</h3>\")\n",
    "    \n",
    "    enable_segmentation = widgets.Checkbox(value=True, description='Segmentation', indent=False)\n",
    "    enable_preprocessing = widgets.Checkbox(value=True, description='Preprocessing', indent=False)\n",
    "    enable_core_analysis = widgets.Checkbox(value=True, description='Core Analysis', indent=False)\n",
    "    enable_porosity = widgets.Checkbox(value=True, description='Porosity Analysis', indent=False)\n",
    "    enable_filament = widgets.Checkbox(value=True, description='Filament Analysis', indent=False)\n",
    "    enable_flow = widgets.Checkbox(value=False, description='Flow Analysis', indent=False)\n",
    "    enable_thermal = widgets.Checkbox(value=False, description='Thermal Analysis', indent=False)\n",
    "    enable_energy = widgets.Checkbox(value=False, description='Energy Analysis', indent=False)\n",
    "    enable_dimensional = widgets.Checkbox(value=False, description='Dimensional Accuracy', indent=False)\n",
    "    enable_uncertainty = widgets.Checkbox(value=True, description='Uncertainty Analysis', indent=False)\n",
    "    \n",
    "    # Segmentation parameters\n",
    "    segmentation_method = widgets.Dropdown(\n",
    "        options=['otsu', 'adaptive', 'manual'],\n",
    "        value='otsu',\n",
    "        description='Segmentation:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    filter_volume_check = widgets.Checkbox(value=False, description='Filter by Volume', indent=False)\n",
    "    min_volume = widgets.FloatText(value=0.0, description='Min Volume (mm¬≥):', style={'description_width': 'initial'}, disabled=True)\n",
    "    \n",
    "    # Flow parameters\n",
    "    flow_direction = widgets.Dropdown(\n",
    "        options=['X', 'Y', 'Z'],\n",
    "        value='Z',\n",
    "        description='Flow Direction:',\n",
    "        style={'description_width': 'initial'},\n",
    "        disabled=True\n",
    "    )\n",
    "    \n",
    "    # Thermal parameters\n",
    "    thermal_conductivity = widgets.FloatText(\n",
    "        value=50.0,\n",
    "        description='Thermal Conductivity (W/m¬∑K):',\n",
    "        style={'description_width': 'initial'},\n",
    "        disabled=True\n",
    "    )\n",
    "    \n",
    "    # Energy parameters\n",
    "    temperature_gradient = widgets.FloatText(\n",
    "        value=50.0,\n",
    "        description='Temperature Gradient (K):',\n",
    "        style={'description_width': 'initial'},\n",
    "        disabled=True\n",
    "    )\n",
    "    \n",
    "    # Dimensional parameters\n",
    "    design_dim_x = widgets.FloatText(value=10.0, description='Design X (mm):', style={'description_width': 'initial'}, disabled=True)\n",
    "    design_dim_y = widgets.FloatText(value=10.0, description='Design Y (mm):', style={'description_width': 'initial'}, disabled=True)\n",
    "    design_dim_z = widgets.FloatText(value=10.0, description='Design Z (mm):', style={'description_width': 'initial'}, disabled=True)\n",
    "    tolerance = widgets.FloatText(value=0.1, description='Tolerance (mm):', style={'description_width': 'initial'}, disabled=True)\n",
    "    \n",
    "    # ============================================\n",
    "    # Section 3: Run Pipeline\n",
    "    # ============================================\n",
    "    \n",
    "    run_pipeline_button = widgets.Button(\n",
    "        description='üöÄ Run Complete Pipeline',\n",
    "        button_style='success',\n",
    "        layout=widgets.Layout(width='250px', height='50px')\n",
    "    )\n",
    "    \n",
    "    pipeline_results_display = widgets.HTML(\n",
    "        value=\"<p><i>No pipeline results</i></p>\",\n",
    "        layout=widgets.Layout(height='300px', overflow='auto')\n",
    "    )\n",
    "    \n",
    "    pipeline_visualization = Output(layout=widgets.Layout(height='500px'))\n",
    "    \n",
    "    # ============================================\n",
    "    # Section 4: Export and Reporting\n",
    "    # ============================================\n",
    "    \n",
    "    output_directory = widgets.Text(\n",
    "        value='output',\n",
    "        placeholder='Output directory path',\n",
    "        description='Output Dir:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    export_format = widgets.Dropdown(\n",
    "        options=['JSON', 'CSV', 'Excel', 'All'],\n",
    "        value='All',\n",
    "        description='Export Format:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    generate_report_check = widgets.Checkbox(value=True, description='Generate HTML Report', indent=False)\n",
    "    export_dragonfly_check = widgets.Checkbox(value=False, description='Export to DragonFly', indent=False)\n",
    "    create_reproducibility_check = widgets.Checkbox(value=True, description='Create Reproducibility Package', indent=False)\n",
    "    \n",
    "    export_button = widgets.Button(\n",
    "        description='üíæ Export Results',\n",
    "        button_style='info',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    export_status_display = widgets.HTML(\n",
    "        value=\"<p><i>No exports</i></p>\",\n",
    "        layout=widgets.Layout(height='150px', overflow='auto')\n",
    "    )\n",
    "    \n",
    "    # ============================================\n",
    "    # Progress and Status\n",
    "    # ============================================\n",
    "    \n",
    "    progress_bar = widgets.IntProgress(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=100,\n",
    "        description='Progress:',\n",
    "        style={'bar_color': '#2ecc71'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "    \n",
    "    status_display = widgets.HTML(\n",
    "        value=\"<p>Ready</p>\",\n",
    "        layout=widgets.Layout(height='60px', overflow='auto')\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Widgets created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Callback functions attached!\n"
     ]
    }
   ],
   "source": [
    "if WIDGETS_AVAILABLE:\n",
    "    \n",
    "    def load_volume_callback(button):\n",
    "        \"\"\"Load volume\"\"\"\n",
    "        global analyzer\n",
    "        \n",
    "        file_path = file_path_text.value.strip()\n",
    "        if not file_path:\n",
    "            status_display.value = \"<p style='color: red;'>Please enter a file path</p>\"\n",
    "            return\n",
    "        \n",
    "        # Normalize path for cross-platform compatibility (Windows, Linux, macOS, WSL)\n",
    "        file_path_obj = normalize_path(file_path, base_path=project_root / 'data')\n",
    "        if not file_path_obj.exists():\n",
    "            # Try relative to project root\n",
    "            file_path_obj = normalize_path(file_path, base_path=project_root)\n",
    "            if not file_path_obj.exists():\n",
    "                status_display.value = f\"<p style='color: red;'>File not found: {file_path}</p>\"\n",
    "                return\n",
    "        \n",
    "        status_display.value = \"<p>Loading volume...</p>\"\n",
    "        progress_bar.value = 20\n",
    "        \n",
    "        try:\n",
    "            voxel_size = (float(voxel_size_x.value), float(voxel_size_y.value), float(voxel_size_z.value))\n",
    "            analyzer = XCTAnalyzer(voxel_size=voxel_size, target_unit='mm')\n",
    "            progress_bar.value = 40\n",
    "            \n",
    "            analyzer.load_volume(str(file_path_obj), normalize=True)\n",
    "            progress_bar.value = 80\n",
    "            \n",
    "            info_html = f\"\"\"\n",
    "            <h4>Volume Information</h4>\n",
    "            <p><b>Shape:</b> {analyzer.volume.shape}</p>\n",
    "            <p><b>Voxel Size:</b> {voxel_size} mm</p>\n",
    "            <p><b>Volume Size:</b> {analyzer.volume.nbytes / (1024**2):.2f} MB</p>\n",
    "            \"\"\"\n",
    "            volume_info_display.value = info_html\n",
    "            \n",
    "            progress_bar.value = 100\n",
    "            status_display.value = \"<p style='color: green;'>‚úÖ Volume loaded successfully!</p>\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            status_display.value = f\"<p style='color: red;'>Error loading volume: {e}</p>\"\n",
    "            progress_bar.value = 0\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    def run_pipeline_callback(button):\n",
    "        \"\"\"Run complete analysis pipeline\"\"\"\n",
    "        global analyzer, pipeline_results\n",
    "        \n",
    "        if analyzer is None or analyzer.volume is None:\n",
    "            status_display.value = \"<p style='color: red;'>Please load a volume first</p>\"\n",
    "            return\n",
    "        \n",
    "        status_display.value = \"<p>Running complete pipeline...</p>\"\n",
    "        progress_bar.value = 0\n",
    "        \n",
    "        try:\n",
    "            voxel_size = analyzer.voxel_size\n",
    "            sample_name = sample_name_text.value.strip() or 'sample'\n",
    "            results = {}\n",
    "            \n",
    "            # Step 1: Segmentation\n",
    "            if enable_segmentation.value:\n",
    "                progress_bar.value = 5\n",
    "                status_display.value = \"<p>Step 1/10: Segmenting volume...</p>\"\n",
    "                analyzer.segment(method=segmentation_method.value, refine=True)\n",
    "                results['segmentation'] = {'method': segmentation_method.value, 'complete': True}\n",
    "            \n",
    "            # Step 2: Preprocessing\n",
    "            if enable_preprocessing.value and analyzer.segmented_volume is not None:\n",
    "                progress_bar.value = 15\n",
    "                status_display.value = \"<p>Step 2/10: Preprocessing...</p>\"\n",
    "                filters = {}\n",
    "                if filter_volume_check.value:\n",
    "                    filters['min_volume'] = float(min_volume.value)\n",
    "                if filters:\n",
    "                    filtered_volume, filter_stats = apply_filters(\n",
    "                        analyzer.segmented_volume, voxel_size, filters\n",
    "                    )\n",
    "                    analyzer.segmented_volume = filtered_volume\n",
    "                    results['preprocessing'] = filter_stats\n",
    "            \n",
    "            # Step 3: Core Analysis\n",
    "            if enable_core_analysis.value and analyzer.segmented_volume is not None:\n",
    "                progress_bar.value = 25\n",
    "                status_display.value = \"<p>Step 3/10: Computing core metrics...</p>\"\n",
    "                metrics = analyzer.compute_metrics()\n",
    "                results['core_metrics'] = metrics\n",
    "            \n",
    "            # Step 4: Porosity Analysis\n",
    "            if enable_porosity.value and analyzer.segmented_volume is not None:\n",
    "                progress_bar.value = 35\n",
    "                status_display.value = \"<p>Step 4/10: Analyzing porosity...</p>\"\n",
    "                porosity_results = analyze_porosity_distribution(\n",
    "                    analyzer.segmented_volume, voxel_size, printing_direction='z'\n",
    "                )\n",
    "                results['porosity'] = {k: v for k, v in porosity_results.items() if k != 'local_porosity_map'}\n",
    "            \n",
    "            # Step 5: Filament Analysis\n",
    "            if enable_filament.value and analyzer.segmented_volume is not None:\n",
    "                progress_bar.value = 45\n",
    "                status_display.value = \"<p>Step 5/10: Analyzing filaments...</p>\"\n",
    "                filament_results = estimate_filament_diameter(\n",
    "                    analyzer.segmented_volume, voxel_size, direction='z'\n",
    "                )\n",
    "                results['filament'] = filament_results\n",
    "            \n",
    "            # Step 6: Flow Analysis\n",
    "            if enable_flow.value and analyzer.segmented_volume is not None:\n",
    "                progress_bar.value = 55\n",
    "                status_display.value = \"<p>Step 6/10: Analyzing flow...</p>\"\n",
    "                flow_results = comprehensive_flow_analysis(\n",
    "                    analyzer.segmented_volume, flow_direction=flow_direction.value.lower(), voxel_size=voxel_size\n",
    "                )\n",
    "                results['flow'] = {k: {kk: vv for kk, vv in v.items() if not isinstance(vv, np.ndarray)} \n",
    "                                  for k, v in flow_results.items() if isinstance(v, dict)}\n",
    "            \n",
    "            # Step 7: Thermal Analysis\n",
    "            if enable_thermal.value and analyzer.segmented_volume is not None:\n",
    "                progress_bar.value = 65\n",
    "                status_display.value = \"<p>Step 7/10: Analyzing thermal...</p>\"\n",
    "                material_properties = {'thermal_conductivity': float(thermal_conductivity.value)}\n",
    "                thermal_results = compute_thermal_resistance(\n",
    "                    analyzer.segmented_volume, voxel_size, material_properties\n",
    "                )\n",
    "                results['thermal'] = thermal_results\n",
    "            \n",
    "            # Step 8: Energy Analysis\n",
    "            if enable_energy.value and analyzer.segmented_volume is not None:\n",
    "                progress_bar.value = 75\n",
    "                status_display.value = \"<p>Step 8/10: Analyzing energy conversion...</p>\"\n",
    "                energy_results = estimate_power_output(\n",
    "                    analyzer.segmented_volume, voxel_size,\n",
    "                    temperature_gradient=float(temperature_gradient.value)\n",
    "                )\n",
    "                results['energy'] = energy_results\n",
    "            \n",
    "            # Step 9: Dimensional Accuracy\n",
    "            if enable_dimensional.value and analyzer.segmented_volume is not None:\n",
    "                progress_bar.value = 85\n",
    "                status_display.value = \"<p>Step 9/10: Analyzing dimensional accuracy...</p>\"\n",
    "                design_specs = {\n",
    "                    'dimensions': {\n",
    "                        'x': float(design_dim_x.value),\n",
    "                        'y': float(design_dim_y.value),\n",
    "                        'z': float(design_dim_z.value)\n",
    "                    },\n",
    "                    'tolerance': float(tolerance.value)\n",
    "                }\n",
    "                dimensional_results = comprehensive_dimensional_analysis(\n",
    "                    analyzer.segmented_volume, voxel_size, design_specs=design_specs\n",
    "                )\n",
    "                results['dimensional'] = {k: v for k, v in dimensional_results.items() \n",
    "                                        if not isinstance(v, (np.ndarray, dict)) or k == 'summary'}\n",
    "            \n",
    "            # Step 10: Uncertainty Analysis\n",
    "            if enable_uncertainty.value and analyzer.segmented_volume is not None:\n",
    "                progress_bar.value = 90\n",
    "                status_display.value = \"<p>Step 10/10: Analyzing uncertainty...</p>\"\n",
    "                if 'core_metrics' in results:\n",
    "                    uncertainty_results = comprehensive_uncertainty_analysis(\n",
    "                        analyzer.segmented_volume, voxel_size, metrics=results['core_metrics']\n",
    "                    )\n",
    "                    results['uncertainty'] = {k: v for k, v in uncertainty_results.items() \n",
    "                                              if not isinstance(v, (np.ndarray, dict)) or k in ['confidence_intervals', 'summary']}\n",
    "            \n",
    "            pipeline_results = results\n",
    "            progress_bar.value = 100\n",
    "            \n",
    "            # Display results summary\n",
    "            html = f\"\"\"\n",
    "            <h4>üöÄ Complete Pipeline Results</h4>\n",
    "            <p><b>Sample:</b> {sample_name}</p>\n",
    "            <p><b>Analysis Steps Completed:</b> {len(results)}</p>\n",
    "            <h5>Results Summary:</h5>\n",
    "            <ul>\n",
    "            \"\"\"\n",
    "            for step_name, step_results in results.items():\n",
    "                if isinstance(step_results, dict):\n",
    "                    html += f\"<li><b>{step_name.replace('_', ' ').title()}:</b> ‚úÖ Complete</li>\"\n",
    "                else:\n",
    "                    html += f\"<li><b>{step_name.replace('_', ' ').title()}:</b> {step_results}</li>\"\n",
    "            html += \"</ul>\"\n",
    "            \n",
    "            # Add key metrics if available\n",
    "            if 'core_metrics' in results:\n",
    "                html += \"<h5>Key Metrics:</h5><ul>\"\n",
    "                key_metrics = ['volume', 'surface_area', 'void_fraction', 'relative_density']\n",
    "                for metric in key_metrics:\n",
    "                    if metric in results['core_metrics']:\n",
    "                        value = results['core_metrics'][metric]\n",
    "                        html += f\"<li><b>{metric.replace('_', ' ').title()}:</b> {value:.4f}</li>\"\n",
    "                html += \"</ul>\"\n",
    "            \n",
    "            pipeline_results_display.value = html\n",
    "            \n",
    "            # Visualize\n",
    "            with pipeline_visualization:\n",
    "                clear_output()\n",
    "                fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "                \n",
    "                # Metrics summary\n",
    "                if 'core_metrics' in results:\n",
    "                    metrics = results['core_metrics']\n",
    "                    key_metrics = ['volume', 'surface_area', 'void_fraction', 'relative_density']\n",
    "                    values = [metrics.get(m, 0) for m in key_metrics]\n",
    "                    axes[0, 0].bar([m.replace('_', ' ').title() for m in key_metrics], values, alpha=0.7)\n",
    "                    axes[0, 0].set_ylabel('Value', fontsize=11)\n",
    "                    axes[0, 0].set_title('Core Metrics Summary', fontsize=12, fontweight='bold')\n",
    "                    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "                    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "                \n",
    "                # Analysis steps completed\n",
    "                step_names = list(results.keys())\n",
    "                axes[0, 1].barh(step_names, [1] * len(step_names), alpha=0.7, color='green')\n",
    "                axes[0, 1].set_xlabel('Status', fontsize=11)\n",
    "                axes[0, 1].set_title('Analysis Steps Completed', fontsize=12, fontweight='bold')\n",
    "                axes[0, 1].set_xlim([0, 1.2])\n",
    "                \n",
    "                # Porosity if available\n",
    "                if 'porosity' in results:\n",
    "                    porosity_data = results['porosity']\n",
    "                    if 'porosity_profile' in porosity_data:\n",
    "                        profile = porosity_data['porosity_profile']\n",
    "                        if isinstance(profile, dict) and 'porosity' in profile:\n",
    "                            axes[1, 0].plot(profile['porosity'], linewidth=2)\n",
    "                            axes[1, 0].set_xlabel('Position', fontsize=11)\n",
    "                            axes[1, 0].set_ylabel('Porosity', fontsize=11)\n",
    "                            axes[1, 0].set_title('Porosity Profile', fontsize=12, fontweight='bold')\n",
    "                            axes[1, 0].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Energy if available\n",
    "                if 'energy' in results:\n",
    "                    energy_data = results['energy']\n",
    "                    power_output = energy_data.get('power_output', 0)\n",
    "                    efficiency = energy_data.get('power_output', 0) / energy_data.get('heat_transfer_rate', 1) * 100 if energy_data.get('heat_transfer_rate', 0) > 0 else 0\n",
    "                    axes[1, 1].bar(['Power Output\\n(mW)', 'Efficiency\\n(%)'], \n",
    "                                 [power_output * 1000, efficiency], alpha=0.7, color=['steelblue', 'coral'])\n",
    "                    axes[1, 1].set_ylabel('Value', fontsize=11)\n",
    "                    axes[1, 1].set_title('Energy Conversion', fontsize=12, fontweight='bold')\n",
    "                    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            \n",
    "            status_display.value = \"<p style='color: green;'>‚úÖ Complete pipeline finished successfully!</p>\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            status_display.value = f\"<p style='color: red;'>Error in pipeline: {e}</p>\"\n",
    "            progress_bar.value = 0\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    def export_callback(button):\n",
    "        \"\"\"Export results and generate reports\"\"\"\n",
    "        global analyzer, pipeline_results\n",
    "        \n",
    "        if not pipeline_results:\n",
    "            status_display.value = \"<p style='color: red;'>Please run pipeline first</p>\"\n",
    "            return\n",
    "        \n",
    "        output_dir = output_directory.value.strip() or 'output'\n",
    "        output_path = Path(output_dir)\n",
    "        if not output_path.is_absolute():\n",
    "            output_path = project_root / output_dir\n",
    "        \n",
    "        status_display.value = \"<p>Exporting results...</p>\"\n",
    "        progress_bar.value = 10\n",
    "        \n",
    "        try:\n",
    "            output_path.mkdir(parents=True, exist_ok=True)\n",
    "            sample_name = sample_name_text.value.strip() or 'sample'\n",
    "            exported_files = []\n",
    "            \n",
    "            # Export results in selected format\n",
    "            export_fmt = export_format.value.lower()\n",
    "            progress_bar.value = 20\n",
    "            \n",
    "            if export_fmt in ['json', 'all']:\n",
    "                json_path = output_path / f'{sample_name}_results.json'\n",
    "                with open(json_path, 'w') as f:\n",
    "                    json.dump(pipeline_results, f, indent=2, default=str)\n",
    "                exported_files.append(str(json_path))\n",
    "            \n",
    "            if export_fmt in ['csv', 'all']:\n",
    "                # Flatten results for CSV\n",
    "                flat_results = {}\n",
    "                def flatten_dict(d, parent_key='', sep='_'):\n",
    "                    items = []\n",
    "                    for k, v in d.items():\n",
    "                        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "                        if isinstance(v, dict):\n",
    "                            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "                        else:\n",
    "                            items.append((new_key, v))\n",
    "                    return dict(items)\n",
    "                \n",
    "                flat_data = flatten_dict(pipeline_results)\n",
    "                df = pd.DataFrame([flat_data])\n",
    "                csv_path = output_path / f'{sample_name}_results.csv'\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                exported_files.append(str(csv_path))\n",
    "            \n",
    "            if export_fmt in ['excel', 'all']:\n",
    "                # Create Excel with multiple sheets\n",
    "                excel_path = output_path / f'{sample_name}_results.xlsx'\n",
    "                with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "                    # Summary sheet\n",
    "                    summary_data = {'Metric': [], 'Value': []}\n",
    "                    if 'core_metrics' in pipeline_results:\n",
    "                        for k, v in pipeline_results['core_metrics'].items():\n",
    "                            if isinstance(v, (int, float)):\n",
    "                                summary_data['Metric'].append(k)\n",
    "                                summary_data['Value'].append(v)\n",
    "                    pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)\n",
    "                    \n",
    "                    # Individual sheets for each analysis type\n",
    "                    for analysis_type, analysis_data in pipeline_results.items():\n",
    "                        if isinstance(analysis_data, dict):\n",
    "                            flat_data = {}\n",
    "                            def extract_values(d, prefix=''):\n",
    "                                for k, v in d.items():\n",
    "                                    if isinstance(v, (int, float, str, bool)):\n",
    "                                        flat_data[f\"{prefix}{k}\"] = v\n",
    "                                    elif isinstance(v, dict):\n",
    "                                        extract_values(v, prefix=f\"{k}_\")\n",
    "                            extract_values(analysis_data)\n",
    "                            if flat_data:\n",
    "                                pd.DataFrame([flat_data]).to_excel(writer, sheet_name=analysis_type, index=False)\n",
    "                exported_files.append(str(excel_path))\n",
    "            \n",
    "            progress_bar.value = 50\n",
    "            \n",
    "            # Generate HTML report\n",
    "            if generate_report_check.value and analyzer is not None:\n",
    "                progress_bar.value = 60\n",
    "                try:\n",
    "                    analyzer.generate_report(str(output_path), sample_name)\n",
    "                    exported_files.append(str(output_path / f'{sample_name}_report.html'))\n",
    "                except Exception as e:\n",
    "                    status_display.value = f\"<p style='color: orange;'>Warning: Could not generate HTML report: {e}</p>\"\n",
    "            \n",
    "            # Export to DragonFly\n",
    "            if export_dragonfly_check.value and analyzer is not None and analyzer.segmented_volume is not None:\n",
    "                progress_bar.value = 70\n",
    "                try:\n",
    "                    dragonfly_dir = output_path / 'dragonfly_export'\n",
    "                    dragonfly_results = comprehensive_dragonfly_integration(\n",
    "                        analyzer.segmented_volume, analyzer.voxel_size,\n",
    "                        analysis_results=pipeline_results,\n",
    "                        output_dir=dragonfly_dir,\n",
    "                        sample_name=sample_name\n",
    "                    )\n",
    "                    exported_files.append(str(dragonfly_dir))\n",
    "                except Exception as e:\n",
    "                    status_display.value = f\"<p style='color: orange;'>Warning: Could not export to DragonFly: {e}</p>\"\n",
    "            \n",
    "            # Create reproducibility package\n",
    "            if create_reproducibility_check.value:\n",
    "                progress_bar.value = 80\n",
    "                try:\n",
    "                    repro_dir = output_path / 'reproducibility_package'\n",
    "                    from src.quality.reproducibility import AnalysisConfig, ProvenanceTracker, SeedManager\n",
    "                    \n",
    "                    # Create config\n",
    "                    config = AnalysisConfig()\n",
    "                    config.set('voxel_size', analyzer.voxel_size if analyzer else (0.1, 0.1, 0.1))\n",
    "                    config.set('segmentation_method', segmentation_method.value)\n",
    "                    \n",
    "                    # Create provenance tracker\n",
    "                    provenance = ProvenanceTracker()\n",
    "                    provenance.add_step('load_volume', {'file_path': file_path_text.value})\n",
    "                    provenance.add_step('pipeline_execution', {'steps': list(pipeline_results.keys())})\n",
    "                    \n",
    "                    # Export package\n",
    "                    export_reproducibility_package(\n",
    "                        repro_dir,\n",
    "                        config=config,\n",
    "                        provenance=provenance,\n",
    "                        results=pipeline_results,\n",
    "                        data_files=[file_path_text.value] if file_path_text.value else None\n",
    "                    )\n",
    "                    exported_files.append(str(repro_dir))\n",
    "                except Exception as e:\n",
    "                    status_display.value = f\"<p style='color: orange;'>Warning: Could not create reproducibility package: {e}</p>\"\n",
    "            \n",
    "            progress_bar.value = 100\n",
    "            \n",
    "            # Display export status\n",
    "            html = f\"\"\"\n",
    "            <h4>üíæ Export Complete</h4>\n",
    "            <p><b>Output Directory:</b> {output_path}</p>\n",
    "            <p><b>Files Exported:</b> {len(exported_files)}</p>\n",
    "            <h5>Exported Files:</h5>\n",
    "            <ul>\n",
    "            \"\"\"\n",
    "            for file_path in exported_files:\n",
    "                html += f\"<li>{Path(file_path).name}</li>\"\n",
    "            html += \"</ul>\"\n",
    "            export_status_display.value = html\n",
    "            \n",
    "            status_display.value = f\"<p style='color: green;'>‚úÖ Export complete! Files saved to {output_path}</p>\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            status_display.value = f\"<p style='color: red;'>Error exporting: {e}</p>\"\n",
    "            progress_bar.value = 0\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # Attach callbacks\n",
    "    load_button.on_click(load_volume_callback)\n",
    "    run_pipeline_button.on_click(run_pipeline_callback)\n",
    "    export_button.on_click(export_callback)\n",
    "    \n",
    "    # Enable/disable widgets based on checkboxes\n",
    "    def update_widgets(change):\n",
    "        min_volume.disabled = not filter_volume_check.value\n",
    "        flow_direction.disabled = not enable_flow.value\n",
    "        thermal_conductivity.disabled = not enable_thermal.value\n",
    "        temperature_gradient.disabled = not enable_energy.value\n",
    "        design_dim_x.disabled = not enable_dimensional.value\n",
    "        design_dim_y.disabled = not enable_dimensional.value\n",
    "        design_dim_z.disabled = not enable_dimensional.value\n",
    "        tolerance.disabled = not enable_dimensional.value\n",
    "    \n",
    "    filter_volume_check.observe(update_widgets, names='value')\n",
    "    enable_flow.observe(update_widgets, names='value')\n",
    "    enable_thermal.observe(update_widgets, names='value')\n",
    "    enable_energy.observe(update_widgets, names='value')\n",
    "    enable_dimensional.observe(update_widgets, names='value')\n",
    "    \n",
    "    print(\"‚úÖ Callback functions attached!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9f0d07ef254f4c915dd6fbab6a429a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1>üöÄ Complete Analysis Pipeline</h1>'), VBox(children=(HTML(value='<h2>üìÇ Load Volu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Dashboard displayed! Configure and run your complete analysis pipeline.\n",
      "\n",
      "üí° Tips:\n",
      "   1. Load your XCT volume\n",
      "   2. Select which analysis modules to include\n",
      "   3. Configure parameters for each module\n",
      "   4. Run the complete pipeline\n",
      "   5. Export results in multiple formats\n",
      "   6. Generate reports and reproducibility packages\n"
     ]
    }
   ],
   "source": [
    "if WIDGETS_AVAILABLE:\n",
    "    \n",
    "    # Create loading panel\n",
    "    loading_panel = widgets.VBox([\n",
    "        widgets.HTML(\"<h2>üìÇ Load Volume</h2>\"),\n",
    "        HBox([\n",
    "            file_path_text,\n",
    "            file_format_dropdown\n",
    "        ]),\n",
    "        HBox([\n",
    "            widgets.HTML(\"<b>Voxel Size:</b>\"),\n",
    "            voxel_size_x,\n",
    "            voxel_size_y,\n",
    "            voxel_size_z\n",
    "        ]),\n",
    "        sample_name_text,\n",
    "        HBox([load_button, volume_info_display])\n",
    "    ])\n",
    "    \n",
    "    # Create configuration panel\n",
    "    config_panel = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üìã Pipeline Configuration</h3>\"),\n",
    "        widgets.HTML(\"<b>Analysis Modules:</b>\"),\n",
    "        enable_segmentation,\n",
    "        enable_preprocessing,\n",
    "        enable_core_analysis,\n",
    "        enable_porosity,\n",
    "        enable_filament,\n",
    "        enable_flow,\n",
    "        enable_thermal,\n",
    "        enable_energy,\n",
    "        enable_dimensional,\n",
    "        enable_uncertainty,\n",
    "        widgets.HTML(\"<hr>\"),\n",
    "        widgets.HTML(\"<b>Parameters:</b>\"),\n",
    "        segmentation_method,\n",
    "        HBox([filter_volume_check, min_volume]),\n",
    "        flow_direction,\n",
    "        thermal_conductivity,\n",
    "        temperature_gradient,\n",
    "        HBox([design_dim_x, design_dim_y, design_dim_z]),\n",
    "        tolerance\n",
    "    ])\n",
    "    \n",
    "    # Create pipeline panel\n",
    "    pipeline_panel = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üöÄ Pipeline Execution</h3>\"),\n",
    "        run_pipeline_button,\n",
    "        pipeline_results_display,\n",
    "        pipeline_visualization\n",
    "    ])\n",
    "    \n",
    "    # Create export panel\n",
    "    export_panel = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üíæ Export and Reporting</h3>\"),\n",
    "        output_directory,\n",
    "        export_format,\n",
    "        generate_report_check,\n",
    "        export_dragonfly_check,\n",
    "        create_reproducibility_check,\n",
    "        export_button,\n",
    "        export_status_display\n",
    "    ])\n",
    "    \n",
    "    # Create tabs for organized display\n",
    "    main_tabs = Tab(children=[\n",
    "        config_panel,\n",
    "        pipeline_panel,\n",
    "        export_panel\n",
    "    ])\n",
    "    main_tabs.set_title(0, 'üìã Config')\n",
    "    main_tabs.set_title(1, 'üöÄ Pipeline')\n",
    "    main_tabs.set_title(2, 'üíæ Export')\n",
    "    \n",
    "    # Create main dashboard\n",
    "    dashboard = widgets.VBox([\n",
    "        widgets.HTML(\"<h1>üöÄ Complete Analysis Pipeline</h1>\"),\n",
    "        loading_panel,\n",
    "        widgets.HTML(\"<hr>\"),\n",
    "        main_tabs,\n",
    "        widgets.HTML(\"<hr>\"),\n",
    "        progress_bar,\n",
    "        status_display\n",
    "    ])\n",
    "    \n",
    "    # Display the dashboard\n",
    "    display(dashboard)\n",
    "    print(\"\\n‚úÖ Dashboard displayed! Configure and run your complete analysis pipeline.\")\n",
    "    print(\"\\nüí° Tips:\")\n",
    "    print(\"   1. Load your XCT volume\")\n",
    "    print(\"   2. Select which analysis modules to include\")\n",
    "    print(\"   3. Configure parameters for each module\")\n",
    "    print(\"   4. Run the complete pipeline\")\n",
    "    print(\"   5. Export results in multiple formats\")\n",
    "    print(\"   6. Generate reports and reproducibility packages\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot display dashboard - ipywidgets not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Complete Pipeline Workflow**:\n",
    "   - End-to-end analysis from data loading to reporting\n",
    "   - Integration of all analysis modules\n",
    "   - Configurable analysis steps\n",
    "   - Progress tracking through all steps\n",
    "\n",
    "2. **Multi-Format Export**:\n",
    "   - JSON export for programmatic access\n",
    "   - CSV export for spreadsheet analysis\n",
    "   - Excel export with multiple sheets\n",
    "   - HTML report generation\n",
    "\n",
    "3. **Reproducibility**:\n",
    "   - Reproducibility package creation\n",
    "   - Configuration saving\n",
    "   - Provenance tracking\n",
    "   - Seed management\n",
    "\n",
    "4. **Integration**:\n",
    "   - DragonFly software export\n",
    "   - External tool compatibility\n",
    "   - Workflow sharing\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Complete pipeline** enables efficient end-to-end analysis\n",
    "- **Modular design** allows selective analysis\n",
    "- **Multiple export formats** support different use cases\n",
    "- **Reproducibility packages** ensure analysis can be repeated\n",
    "- **Integration capabilities** enable collaboration with other tools\n",
    "\n",
    "### Pipeline Workflow\n",
    "\n",
    "```\n",
    "Load Data ‚Üí Segment ‚Üí Preprocess ‚Üí Core Analysis ‚Üí \n",
    "Porosity ‚Üí Filament ‚Üí Flow ‚Üí Thermal ‚Üí Energy ‚Üí \n",
    "Dimensional ‚Üí Uncertainty ‚Üí Export ‚Üí Report\n",
    "```\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Start with core analysis** to understand basic structure\n",
    "2. **Add experimental analysis** for performance insights\n",
    "3. **Include quality control** for validation\n",
    "4. **Export in multiple formats** for different audiences\n",
    "5. **Create reproducibility packages** for sharing\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Framework Documentation](../docs/README.md)\n",
    "- [All Modules](../docs/modules.md)\n",
    "- [Workflows](../docs/workflows.md)\n",
    "- [Tutorials](../docs/tutorials.md)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed all 8 notebooks! You now have a comprehensive understanding of:\n",
    "\n",
    "- ‚úÖ Basic XCT data analysis\n",
    "- ‚úÖ Preprocessing and data cleaning\n",
    "- ‚úÖ Core morphological analysis\n",
    "- ‚úÖ Experimental analysis (flow, thermal, energy)\n",
    "- ‚úÖ Advanced analysis (sensitivity, virtual experiments)\n",
    "- ‚úÖ Comparative analysis and batch processing\n",
    "- ‚úÖ Quality control and validation\n",
    "- ‚úÖ Complete end-to-end pipeline\n",
    "\n",
    "**Next Steps:**\n",
    "- Apply these techniques to your own data\n",
    "- Customize workflows for your research needs\n",
    "- Contribute improvements to the framework\n",
    "- Share your results and insights!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
